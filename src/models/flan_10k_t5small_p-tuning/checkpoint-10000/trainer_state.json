{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.06529077245512892,
  "eval_steps": 500,
  "global_step": 10000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.529261589050293,
      "learning_rate": 0.001993470922754487,
      "loss": 2.2809,
      "step": 500
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6582152843475342,
      "learning_rate": 0.0019869418455089743,
      "loss": 1.639,
      "step": 1000
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3670022487640381,
      "learning_rate": 0.0019804127682634615,
      "loss": 1.5356,
      "step": 1500
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5222371220588684,
      "learning_rate": 0.0019738836910179487,
      "loss": 1.4619,
      "step": 2000
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.24779416620731354,
      "learning_rate": 0.001967354613772436,
      "loss": 1.2899,
      "step": 2500
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2581304907798767,
      "learning_rate": 0.001960825536526923,
      "loss": 1.2895,
      "step": 3000
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.21066556870937347,
      "learning_rate": 0.0019542964592814097,
      "loss": 1.2508,
      "step": 3500
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3866860270500183,
      "learning_rate": 0.001947767382035897,
      "loss": 1.2272,
      "step": 4000
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.33759060502052307,
      "learning_rate": 0.0019412383047903842,
      "loss": 1.2255,
      "step": 4500
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.09009938687086105,
      "learning_rate": 0.0019347092275448711,
      "loss": 1.2615,
      "step": 5000
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5159850716590881,
      "learning_rate": 0.0019281801502993583,
      "loss": 1.197,
      "step": 5500
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.14466635882854462,
      "learning_rate": 0.0019216510730538452,
      "loss": 1.191,
      "step": 6000
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.22515732049942017,
      "learning_rate": 0.0019151219958083324,
      "loss": 1.1625,
      "step": 6500
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1742686629295349,
      "learning_rate": 0.0019085929185628195,
      "loss": 1.2405,
      "step": 7000
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.32412999868392944,
      "learning_rate": 0.0019020638413173067,
      "loss": 1.1948,
      "step": 7500
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.21310998499393463,
      "learning_rate": 0.0018955347640717936,
      "loss": 1.1484,
      "step": 8000
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1779467761516571,
      "learning_rate": 0.0018890056868262808,
      "loss": 1.1982,
      "step": 8500
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.16855110228061676,
      "learning_rate": 0.001882476609580768,
      "loss": 1.216,
      "step": 9000
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.28491583466529846,
      "learning_rate": 0.001875947532335255,
      "loss": 1.2022,
      "step": 9500
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.17400744557380676,
      "learning_rate": 0.0018694184550897422,
      "loss": 1.1512,
      "step": 10000
    }
  ],
  "logging_steps": 500,
  "max_steps": 153161,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 211471564800000.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}

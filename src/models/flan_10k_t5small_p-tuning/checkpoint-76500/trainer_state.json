{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.99561266060796,
  "eval_steps": 500,
  "global_step": 76500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03,
      "grad_norm": 0.6425095796585083,
      "learning_rate": 0.0019869424422855947,
      "loss": 2.1116,
      "step": 500
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.20086631178855896,
      "learning_rate": 0.0019738848845711897,
      "loss": 1.4711,
      "step": 1000
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14173978567123413,
      "learning_rate": 0.0019608273268567847,
      "loss": 1.2802,
      "step": 1500
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.12322109192609787,
      "learning_rate": 0.0019477697691423796,
      "loss": 1.2256,
      "step": 2000
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.11602123826742172,
      "learning_rate": 0.0019347122114279744,
      "loss": 1.2011,
      "step": 2500
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.30166539549827576,
      "learning_rate": 0.0019216546537135695,
      "loss": 1.1743,
      "step": 3000
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.11857517063617706,
      "learning_rate": 0.0019085970959991643,
      "loss": 1.1694,
      "step": 3500
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.10695049166679382,
      "learning_rate": 0.0018955395382847593,
      "loss": 1.1526,
      "step": 4000
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5574894547462463,
      "learning_rate": 0.0018824819805703542,
      "loss": 1.1626,
      "step": 4500
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.11113931983709335,
      "learning_rate": 0.0018694244228559492,
      "loss": 1.1575,
      "step": 5000
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.12579405307769775,
      "learning_rate": 0.001856366865141544,
      "loss": 1.134,
      "step": 5500
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.11947406828403473,
      "learning_rate": 0.0018433093074271387,
      "loss": 1.1406,
      "step": 6000
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.08277256041765213,
      "learning_rate": 0.0018302517497127337,
      "loss": 1.1232,
      "step": 6500
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.09831903129816055,
      "learning_rate": 0.0018171941919983285,
      "loss": 1.1426,
      "step": 7000
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.1012386679649353,
      "learning_rate": 0.0018041366342839236,
      "loss": 1.1319,
      "step": 7500
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.1243402510881424,
      "learning_rate": 0.0017910790765695184,
      "loss": 1.1269,
      "step": 8000
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.1058884859085083,
      "learning_rate": 0.0017780215188551135,
      "loss": 1.1351,
      "step": 8500
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.13067848980426788,
      "learning_rate": 0.0017649639611407083,
      "loss": 1.1398,
      "step": 9000
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.09320927411317825,
      "learning_rate": 0.0017519064034263033,
      "loss": 1.1443,
      "step": 9500
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.09736128896474838,
      "learning_rate": 0.001738848845711898,
      "loss": 1.1299,
      "step": 10000
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.10314242541790009,
      "learning_rate": 0.001725791287997493,
      "loss": 1.1253,
      "step": 10500
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.08027277886867523,
      "learning_rate": 0.0017127337302830878,
      "loss": 1.1283,
      "step": 11000
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.10931183397769928,
      "learning_rate": 0.0016996761725686829,
      "loss": 1.1118,
      "step": 11500
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.15525564551353455,
      "learning_rate": 0.0016866186148542777,
      "loss": 1.1211,
      "step": 12000
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.0996229499578476,
      "learning_rate": 0.0016735610571398725,
      "loss": 1.1042,
      "step": 12500
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.17125175893306732,
      "learning_rate": 0.0016605034994254676,
      "loss": 1.1178,
      "step": 13000
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.08747436851263046,
      "learning_rate": 0.0016474459417110624,
      "loss": 1.1225,
      "step": 13500
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.07956787943840027,
      "learning_rate": 0.0016343883839966572,
      "loss": 1.1183,
      "step": 14000
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.07857260853052139,
      "learning_rate": 0.001621330826282252,
      "loss": 1.1235,
      "step": 14500
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.10690537095069885,
      "learning_rate": 0.0016082732685678471,
      "loss": 1.1191,
      "step": 15000
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.21495063602924347,
      "learning_rate": 0.001595215710853442,
      "loss": 1.113,
      "step": 15500
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.09580740332603455,
      "learning_rate": 0.001582158153139037,
      "loss": 1.1165,
      "step": 16000
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.11240598559379578,
      "learning_rate": 0.0015691005954246318,
      "loss": 1.1,
      "step": 16500
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.09462425112724304,
      "learning_rate": 0.0015560430377102269,
      "loss": 1.0975,
      "step": 17000
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.07916192710399628,
      "learning_rate": 0.0015429854799958217,
      "loss": 1.1198,
      "step": 17500
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.0757719948887825,
      "learning_rate": 0.0015299279222814163,
      "loss": 1.1162,
      "step": 18000
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.1201469823718071,
      "learning_rate": 0.0015168703645670114,
      "loss": 1.1217,
      "step": 18500
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.16630712151527405,
      "learning_rate": 0.0015038128068526062,
      "loss": 1.1088,
      "step": 19000
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.0156464576721191,
      "eval_runtime": 841.7434,
      "eval_samples_per_second": 90.972,
      "eval_steps_per_second": 2.843,
      "step": 19146
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.09610600024461746,
      "learning_rate": 0.0014907552491382012,
      "loss": 1.1202,
      "step": 19500
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.08353938907384872,
      "learning_rate": 0.001477697691423796,
      "loss": 1.1175,
      "step": 20000
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.18772858381271362,
      "learning_rate": 0.0014646401337093911,
      "loss": 1.1111,
      "step": 20500
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.07309887558221817,
      "learning_rate": 0.001451582575994986,
      "loss": 1.1191,
      "step": 21000
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.10711164027452469,
      "learning_rate": 0.001438525018280581,
      "loss": 1.1079,
      "step": 21500
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.15415135025978088,
      "learning_rate": 0.0014254674605661756,
      "loss": 1.1182,
      "step": 22000
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.10991605371236801,
      "learning_rate": 0.0014124099028517707,
      "loss": 1.1182,
      "step": 22500
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.08182452619075775,
      "learning_rate": 0.0013993523451373655,
      "loss": 1.1168,
      "step": 23000
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.08695671707391739,
      "learning_rate": 0.0013862947874229603,
      "loss": 1.1153,
      "step": 23500
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.10473289340734482,
      "learning_rate": 0.0013732372297085554,
      "loss": 1.1107,
      "step": 24000
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.15159352123737335,
      "learning_rate": 0.0013601796719941502,
      "loss": 1.1184,
      "step": 24500
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.12506243586540222,
      "learning_rate": 0.0013471221142797452,
      "loss": 1.1101,
      "step": 25000
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.12680760025978088,
      "learning_rate": 0.00133406455656534,
      "loss": 1.1199,
      "step": 25500
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.11704280227422714,
      "learning_rate": 0.001321006998850935,
      "loss": 1.1027,
      "step": 26000
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.0756637454032898,
      "learning_rate": 0.0013079494411365297,
      "loss": 1.1093,
      "step": 26500
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.12176401168107986,
      "learning_rate": 0.0012948918834221248,
      "loss": 1.1152,
      "step": 27000
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.09120158851146698,
      "learning_rate": 0.0012818343257077196,
      "loss": 1.1152,
      "step": 27500
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.07992297410964966,
      "learning_rate": 0.0012687767679933147,
      "loss": 1.12,
      "step": 28000
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.08879914879798889,
      "learning_rate": 0.0012557192102789095,
      "loss": 1.0989,
      "step": 28500
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.09348761290311813,
      "learning_rate": 0.0012426616525645043,
      "loss": 1.0984,
      "step": 29000
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.10038336366415024,
      "learning_rate": 0.0012296040948500994,
      "loss": 1.1129,
      "step": 29500
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.07952391356229782,
      "learning_rate": 0.001216546537135694,
      "loss": 1.1182,
      "step": 30000
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.10869734734296799,
      "learning_rate": 0.001203488979421289,
      "loss": 1.1023,
      "step": 30500
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.08631936460733414,
      "learning_rate": 0.0011904314217068839,
      "loss": 1.1241,
      "step": 31000
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.09300541877746582,
      "learning_rate": 0.001177373863992479,
      "loss": 1.1064,
      "step": 31500
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.06644774228334427,
      "learning_rate": 0.0011643163062780737,
      "loss": 1.0983,
      "step": 32000
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.07942892611026764,
      "learning_rate": 0.0011512587485636688,
      "loss": 1.116,
      "step": 32500
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.10135223716497421,
      "learning_rate": 0.0011382011908492636,
      "loss": 1.1018,
      "step": 33000
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.10853087157011032,
      "learning_rate": 0.0011251436331348587,
      "loss": 1.1047,
      "step": 33500
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.12002118676900864,
      "learning_rate": 0.0011120860754204533,
      "loss": 1.1183,
      "step": 34000
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.11395306885242462,
      "learning_rate": 0.0010990285177060483,
      "loss": 1.1064,
      "step": 34500
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.1381346583366394,
      "learning_rate": 0.0010859709599916432,
      "loss": 1.1066,
      "step": 35000
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.1112644374370575,
      "learning_rate": 0.001072913402277238,
      "loss": 1.0998,
      "step": 35500
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.09410655498504639,
      "learning_rate": 0.001059855844562833,
      "loss": 1.111,
      "step": 36000
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.08435047417879105,
      "learning_rate": 0.0010467982868484279,
      "loss": 1.1077,
      "step": 36500
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.10156828910112381,
      "learning_rate": 0.001033740729134023,
      "loss": 1.0957,
      "step": 37000
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.38719621300697327,
      "learning_rate": 0.0010206831714196177,
      "loss": 1.0873,
      "step": 37500
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.1085277646780014,
      "learning_rate": 0.0010076256137052126,
      "loss": 1.0909,
      "step": 38000
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.01138174533844,
      "eval_runtime": 1071.4904,
      "eval_samples_per_second": 71.466,
      "eval_steps_per_second": 2.233,
      "step": 38292
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.08977357298135757,
      "learning_rate": 0.0009945680559908074,
      "loss": 1.0982,
      "step": 38500
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.08211399614810944,
      "learning_rate": 0.0009815104982764025,
      "loss": 1.0972,
      "step": 39000
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.10099902004003525,
      "learning_rate": 0.0009684529405619973,
      "loss": 1.1088,
      "step": 39500
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.08878467231988907,
      "learning_rate": 0.0009553953828475922,
      "loss": 1.1017,
      "step": 40000
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.08961553871631622,
      "learning_rate": 0.0009423378251331872,
      "loss": 1.1081,
      "step": 40500
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.09187721461057663,
      "learning_rate": 0.000929280267418782,
      "loss": 1.1035,
      "step": 41000
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.08680212497711182,
      "learning_rate": 0.0009162227097043769,
      "loss": 1.1026,
      "step": 41500
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.09880343824625015,
      "learning_rate": 0.0009031651519899719,
      "loss": 1.1012,
      "step": 42000
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.08609288930892944,
      "learning_rate": 0.0008901075942755668,
      "loss": 1.1092,
      "step": 42500
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.0875660702586174,
      "learning_rate": 0.0008770500365611616,
      "loss": 1.0962,
      "step": 43000
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.10867851227521896,
      "learning_rate": 0.0008639924788467565,
      "loss": 1.0897,
      "step": 43500
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.08405737578868866,
      "learning_rate": 0.0008509349211323514,
      "loss": 1.0904,
      "step": 44000
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.13246509432792664,
      "learning_rate": 0.0008378773634179463,
      "loss": 1.1015,
      "step": 44500
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.13466519117355347,
      "learning_rate": 0.0008248198057035412,
      "loss": 1.1104,
      "step": 45000
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.10650130361318588,
      "learning_rate": 0.0008117622479891361,
      "loss": 1.1089,
      "step": 45500
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.12494467943906784,
      "learning_rate": 0.000798704690274731,
      "loss": 1.1045,
      "step": 46000
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.11065904796123505,
      "learning_rate": 0.000785647132560326,
      "loss": 1.117,
      "step": 46500
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.10103196650743484,
      "learning_rate": 0.0007725895748459208,
      "loss": 1.1004,
      "step": 47000
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.10861080139875412,
      "learning_rate": 0.0007595320171315158,
      "loss": 1.1119,
      "step": 47500
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.10336662083864212,
      "learning_rate": 0.0007464744594171107,
      "loss": 1.0953,
      "step": 48000
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.09196507930755615,
      "learning_rate": 0.0007334169017027056,
      "loss": 1.0976,
      "step": 48500
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.11937376856803894,
      "learning_rate": 0.0007203593439883005,
      "loss": 1.1036,
      "step": 49000
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.08608503639698029,
      "learning_rate": 0.0007073017862738953,
      "loss": 1.1065,
      "step": 49500
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.09234970808029175,
      "learning_rate": 0.0006942442285594902,
      "loss": 1.0996,
      "step": 50000
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.17790229618549347,
      "learning_rate": 0.0006811866708450851,
      "loss": 1.1144,
      "step": 50500
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.16553623974323273,
      "learning_rate": 0.00066812911313068,
      "loss": 1.1102,
      "step": 51000
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.12730012834072113,
      "learning_rate": 0.000655071555416275,
      "loss": 1.0995,
      "step": 51500
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.1258419156074524,
      "learning_rate": 0.0006420139977018699,
      "loss": 1.1294,
      "step": 52000
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.09960265457630157,
      "learning_rate": 0.0006289564399874647,
      "loss": 1.1042,
      "step": 52500
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.08009397238492966,
      "learning_rate": 0.0006158988822730597,
      "loss": 1.1129,
      "step": 53000
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.10980670154094696,
      "learning_rate": 0.0006028413245586546,
      "loss": 1.1216,
      "step": 53500
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.19084465503692627,
      "learning_rate": 0.0005897837668442495,
      "loss": 1.0967,
      "step": 54000
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.12166391313076019,
      "learning_rate": 0.0005767262091298444,
      "loss": 1.1091,
      "step": 54500
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.11362960934638977,
      "learning_rate": 0.0005636686514154392,
      "loss": 1.1184,
      "step": 55000
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.08468335121870041,
      "learning_rate": 0.0005506110937010341,
      "loss": 1.1062,
      "step": 55500
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.11703500896692276,
      "learning_rate": 0.0005375535359866291,
      "loss": 1.1047,
      "step": 56000
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.09406547993421555,
      "learning_rate": 0.0005244959782722239,
      "loss": 1.1065,
      "step": 56500
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.1237257793545723,
      "learning_rate": 0.0005114384205578188,
      "loss": 1.1028,
      "step": 57000
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.0059741735458374,
      "eval_runtime": 199.3354,
      "eval_samples_per_second": 384.152,
      "eval_steps_per_second": 12.005,
      "step": 57438
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.10878407955169678,
      "learning_rate": 0.0004983808628434138,
      "loss": 1.1137,
      "step": 57500
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.1126546636223793,
      "learning_rate": 0.00048532330512900866,
      "loss": 1.1012,
      "step": 58000
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.10116595029830933,
      "learning_rate": 0.0004722657474146036,
      "loss": 1.0895,
      "step": 58500
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.1068652868270874,
      "learning_rate": 0.0004592081897001985,
      "loss": 1.097,
      "step": 59000
    },
    {
      "epoch": 3.11,
      "grad_norm": 0.11406129598617554,
      "learning_rate": 0.00044615063198579337,
      "loss": 1.1013,
      "step": 59500
    },
    {
      "epoch": 3.13,
      "grad_norm": 0.1133071631193161,
      "learning_rate": 0.00043309307427138826,
      "loss": 1.1147,
      "step": 60000
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.09178458154201508,
      "learning_rate": 0.0004200355165569832,
      "loss": 1.1028,
      "step": 60500
    },
    {
      "epoch": 3.19,
      "grad_norm": 0.08973733335733414,
      "learning_rate": 0.0004069779588425781,
      "loss": 1.109,
      "step": 61000
    },
    {
      "epoch": 3.21,
      "grad_norm": 0.11700417846441269,
      "learning_rate": 0.000393920401128173,
      "loss": 1.095,
      "step": 61500
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.11176450550556183,
      "learning_rate": 0.0003808628434137679,
      "loss": 1.0992,
      "step": 62000
    },
    {
      "epoch": 3.26,
      "grad_norm": 0.09191803634166718,
      "learning_rate": 0.0003678052856993628,
      "loss": 1.0991,
      "step": 62500
    },
    {
      "epoch": 3.29,
      "grad_norm": 0.09987442195415497,
      "learning_rate": 0.00035474772798495767,
      "loss": 1.0938,
      "step": 63000
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.11544932425022125,
      "learning_rate": 0.0003416901702705526,
      "loss": 1.1088,
      "step": 63500
    },
    {
      "epoch": 3.34,
      "grad_norm": 0.09401191025972366,
      "learning_rate": 0.0003286326125561475,
      "loss": 1.0987,
      "step": 64000
    },
    {
      "epoch": 3.37,
      "grad_norm": 0.0975055918097496,
      "learning_rate": 0.00031557505484174243,
      "loss": 1.1069,
      "step": 64500
    },
    {
      "epoch": 3.39,
      "grad_norm": 0.12300187349319458,
      "learning_rate": 0.00030251749712733727,
      "loss": 1.0974,
      "step": 65000
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.11539459973573685,
      "learning_rate": 0.0002894599394129322,
      "loss": 1.1229,
      "step": 65500
    },
    {
      "epoch": 3.45,
      "grad_norm": 0.09504951536655426,
      "learning_rate": 0.0002764023816985271,
      "loss": 1.1089,
      "step": 66000
    },
    {
      "epoch": 3.47,
      "grad_norm": 0.08858703821897507,
      "learning_rate": 0.00026334482398412203,
      "loss": 1.0978,
      "step": 66500
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.10153945535421371,
      "learning_rate": 0.0002502872662697169,
      "loss": 1.1057,
      "step": 67000
    },
    {
      "epoch": 3.53,
      "grad_norm": 0.1489993780851364,
      "learning_rate": 0.00023722970855531182,
      "loss": 1.0998,
      "step": 67500
    },
    {
      "epoch": 3.55,
      "grad_norm": 0.11200051754713058,
      "learning_rate": 0.00022417215084090674,
      "loss": 1.0897,
      "step": 68000
    },
    {
      "epoch": 3.58,
      "grad_norm": 0.1132560521364212,
      "learning_rate": 0.00021111459312650165,
      "loss": 1.0901,
      "step": 68500
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.12528645992279053,
      "learning_rate": 0.00019805703541209653,
      "loss": 1.1121,
      "step": 69000
    },
    {
      "epoch": 3.63,
      "grad_norm": 0.10140090435743332,
      "learning_rate": 0.00018499947769769144,
      "loss": 1.1118,
      "step": 69500
    },
    {
      "epoch": 3.66,
      "grad_norm": 0.14209206402301788,
      "learning_rate": 0.00017194191998328636,
      "loss": 1.098,
      "step": 70000
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.12391361594200134,
      "learning_rate": 0.00015888436226888124,
      "loss": 1.1111,
      "step": 70500
    },
    {
      "epoch": 3.71,
      "grad_norm": 0.10526647418737411,
      "learning_rate": 0.00014582680455447615,
      "loss": 1.1284,
      "step": 71000
    },
    {
      "epoch": 3.73,
      "grad_norm": 0.11856064945459366,
      "learning_rate": 0.00013276924684007104,
      "loss": 1.0908,
      "step": 71500
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.12817662954330444,
      "learning_rate": 0.00011971168912566593,
      "loss": 1.1007,
      "step": 72000
    },
    {
      "epoch": 3.79,
      "grad_norm": 0.1569693386554718,
      "learning_rate": 0.00010665413141126085,
      "loss": 1.1097,
      "step": 72500
    },
    {
      "epoch": 3.81,
      "grad_norm": 0.11987201869487762,
      "learning_rate": 9.359657369685574e-05,
      "loss": 1.1038,
      "step": 73000
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.1139817088842392,
      "learning_rate": 8.053901598245064e-05,
      "loss": 1.1078,
      "step": 73500
    },
    {
      "epoch": 3.87,
      "grad_norm": 0.09671659767627716,
      "learning_rate": 6.748145826804554e-05,
      "loss": 1.0888,
      "step": 74000
    },
    {
      "epoch": 3.89,
      "grad_norm": 0.09433531016111374,
      "learning_rate": 5.442390055364045e-05,
      "loss": 1.1078,
      "step": 74500
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.09318415075540543,
      "learning_rate": 4.136634283923535e-05,
      "loss": 1.1135,
      "step": 75000
    },
    {
      "epoch": 3.94,
      "grad_norm": 0.12037098407745361,
      "learning_rate": 2.8308785124830255e-05,
      "loss": 1.121,
      "step": 75500
    },
    {
      "epoch": 3.97,
      "grad_norm": 0.1220807135105133,
      "learning_rate": 1.5251227410425155e-05,
      "loss": 1.1038,
      "step": 76000
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.09787668287754059,
      "learning_rate": 2.1936696960200565e-06,
      "loss": 1.107,
      "step": 76500
    }
  ],
  "logging_steps": 500,
  "max_steps": 76584,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "total_flos": 1.29415839547392e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
